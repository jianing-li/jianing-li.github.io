---
title: "Recent Advances in Neuromorphic Vision Sensors: A Survey"
collection: publications
permalink: /publication/2020-04-29-neuromorpihc-vision-a-survey
excerpt: 
date: 2020-04-29
venue: Chinese Journal of Computers
paperurl:
citation:
---
<a href="https://jianing-li.github.io/files/2019_icme_event_based_enhanced.pdf" target="_blank"><b>PDF</b></a>&emsp;
<a href="https://www.pkuml.org/resources/pku-ddd17-car.html" target="_blank"><b>Datasets</b></a>&emsp;
<a href="https://jianing-li.github.io/files/2019_icme_event_based_enhanced_bibtex.txt" target="_blank"><b>BibTex</b></a>

![joint_detection_framework](/images/joint_detection_framework.jpg){:class="img-responsive"}

<b>Abstract.</b> Due to the high-speed motion blur and low dynamic range, conventional frame-based cameras have encountered an important challenge in object detection, especially in autonomous driving. Event-based cameras, by taking the advantages of high temporal resolution and high dynamic range, have brought a new perspective to address the challenge. Motivated by this fact, this paper proposes a joint framework combining event-based and frame-based vision for vehicle detection. Specially, two separate event-based and framebased streams are incorporated into a convolutional neural network (CNN). Besides, to accommodate the asynchronous events from event-based cameras, a convolutional spiking neural network (SNN) is utilized to generate visual attention maps so that two streams can be synchronized. Moreover, Dempster-Shafer theory is introduced to merge two outputs from CNN in a joint decision model. The experimental results show that the proposed approach outperforms the state-of-theart methods only using frame-based information, especially in fast motion and challenging illumination conditions.

<br />
<b>Reference:</b>
* Jianing Li, Siwei Dong, Zhaofei Yu, Yonghong Tian, Tiejun Huang, "Event-based Enhanced: A Joint Detection Framework in Autonomous Driving", IEEE International Conference on Multimedia and Expro (ICME), 2019.